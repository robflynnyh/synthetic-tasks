

model:
  d_model: 256
  heads: 4
  n_layers: 6

data_gen:
  min_len: 1
  max_len: 50
  sentences_per_example: 1000
  examples_per_batch: 1

#tokenizer_path: ./tokenizer/tokenizer.model

wandb:
  log_dir: /store/store5/data/tmp/wandb/word-occurrence

train:
  checkpoint_folder: "checkpoints"
  num_steps: 50000000

optim:
  lr: 3e-4